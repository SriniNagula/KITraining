import torch
import math
from transformers import AutoModelForCausalLM, AutoTokenizer
from tqdm import tqdm # Optional: for a progress bar

def calculate_corpus_perplexity(file_path, model_id="gpt2"):
    # 1. Setup device (GPU if available, else CPU)
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    # 2. Load model and tokenizer
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    model = AutoModelForCausalLM.from_pretrained(model_id).to(device)
    model.eval() # Set to evaluation mode
    
    total_loss = 0.0
    line_count = 0
    
    # 3. Process the file
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
        
    print(f"Processing {len(lines)} lines...")
    
    for line in tqdm(lines):
        line = line.strip()
        if not line: continue # Skip empty lines
        
        inputs = tokenizer(line, return_tensors="pt").to(device)
        input_ids = inputs["input_ids"]
        
        # Skip lines that are too short for the model to process
        if input_ids.size(1) <= 1:
            continue

        with torch.no_grad():
            outputs = model(input_ids, labels=input_ids)
            # .item() extracts the scalar value from the tensor
            loss = outputs.loss.item() 
            
        total_loss += loss
        line_count += 1
    
    # 4. Calculate final metrics
    if line_count == 0:
        return 0, 0
        
    avg_loss = total_loss / line_count
    avg_perplexity = math.exp(avg_loss)
    
    return avg_loss, avg_perplexity

# --- Usage ---
file_name = "your_data.txt" # Ensure this file exists in your directory
mean_loss, corpus_ppl = calculate_corpus_perplexity(file_name)

print(f"\n--- Final Results ---")
print(f"Average Loss: {mean_loss:.4f}")
print(f"Corpus Perplexity: {corpus_ppl:.2f}")